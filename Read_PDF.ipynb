{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPUIGJHG4O+Ik370i6tcGYF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PARULCHUTANIPC/PythonCodes/blob/readPDF/Read_PDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pip install pytesseract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQ_Hd-unQAKO",
        "outputId": "aa5ee4a4-f281-478a-8b38-9e49e714bbf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.9/dist-packages (0.3.10)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.9/dist-packages (from pytesseract) (23.0)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from pytesseract) (8.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pdf2image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hm9Yo37IQYi7",
        "outputId": "21407af8-dbbd-4e7b-9254-8b70bdd5c177"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.9/dist-packages (1.16.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from pdf2image) (8.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install poppler-utils\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5i1DNT01R0vs",
        "outputId": "26473b71-02f7-4e5b-94d8-741de5f767db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 23 not upgraded.\n",
            "Need to get 174 kB of archives.\n",
            "After this operation, 754 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 poppler-utils amd64 0.86.1-0ubuntu1.1 [174 kB]\n",
            "Fetched 174 kB in 1s (322 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 128285 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_0.86.1-0ubuntu1.1_amd64.deb ...\n",
            "Unpacking poppler-utils (0.86.1-0ubuntu1.1) ...\n",
            "Setting up poppler-utils (0.86.1-0ubuntu1.1) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdf2image\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNv_xZmySAJ1",
        "outputId": "28caffca-8808-4e77-d719-33b6d35472ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.9/dist-packages (1.16.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from pdf2image) (8.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['PATH'] += '/content/Synopsis.pdf'\n"
      ],
      "metadata": {
        "id": "JoqZih4YSGyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install tesseract-ocr\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gt7PU2F_ScUO",
        "outputId": "f5ad3824-7146-49e4-fcac-e3dfdf6b3b61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 23 not upgraded.\n",
            "Need to get 4,850 kB of archives.\n",
            "After this operation, 16.3 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1 [1,598 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 tesseract-ocr amd64 4.1.1-2build2 [262 kB]\n",
            "Fetched 4,850 kB in 1s (5,110 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 128315 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2build2_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2build2) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2build2) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pytesseract\n",
        "from pdf2image import convert_from_path\n",
        "\n",
        "# specify the path to the scanned PDF file\n",
        "pdf_file = '/content/Synopsis.pdf'\n",
        "\n",
        "# convert the PDF file to images using pdf2image\n",
        "pages = convert_from_path(pdf_file)  # 500 is the resolution in DPI\n",
        "\n",
        "# iterate through the pages and extract text using Pytesseract\n",
        "for page in pages:\n",
        "    text = pytesseract.image_to_string(page, lang='eng')\n",
        "    print(text)\n"
      ],
      "metadata": {
        "id": "5Dua1TfiNRz4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6a668e60-5c69-43f2-837f-8ebb288f2ad5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CERTIFICATE\n",
            "\n",
            "This is to certify that the synopsis titled “Deep Learning based Real Time\n",
            "Web Application for Ear Recognition” is submitted by Parul Chutani UID:\n",
            "21YEC1010 pursuing Doctor of Philosophy in Electronics and Communica-\n",
            "tion Engineering Department of University Institute of Engineering, Chandi-\n",
            "\n",
            "garh University.\n",
            "\n",
            "Dated: Signature of the Applicant\n",
            "Parul Chutani\n",
            "\n",
            "UID:21YEC1010\n",
            "\f\n",
            "DECLARATION\n",
            "\n",
            "I, Parul Chutani declare that I have not been registered with any other Univer-\n",
            "sity or Institution for Ph.D. other than the Chandigarh University.\n",
            "\n",
            "Dated: Signature of the Applicant\n",
            "Parul Chutani\n",
            "\n",
            "UID:21YEC1010\n",
            "\n",
            "I recommend that synopsis has been drafted according to the approved format\n",
            "of the university. It is also certified that the applicant has not been registered\n",
            "as Ph.D. student in any other University or Institution. The submitted synopsis\n",
            "entitled “Deep Learning based Real Time Web Application for Ear Recognition”\n",
            "\n",
            "has not been submitted else for consideration.\n",
            "\n",
            "Signature of Supervisor:\n",
            "\n",
            "Signature: Signature & stamp of\n",
            "Research Coordinator\n",
            "Principal/Director/Chairperson\n",
            "of College/ Institute\n",
            "Centre/ Department\n",
            "\n",
            "Research Committee\n",
            "\n",
            "il\n",
            "\f\n",
            "ACKNOWLEDGEMENT\n",
            "\n",
            "This synopsis in itself is an acknowledgement to the inspiration, drive and tech-\n",
            "nical assistance contributed to it by many people. It would have never been\n",
            "\n",
            "possible without the help and guidance that I received from them.\n",
            "\n",
            "Firstly, I express my profound sense of gratitude to Dr. Sanjeet Singh, Dean\n",
            "Research, and Dr. Harjot Singh Gill, Director Engineering (UIE),\n",
            "Chandigarh University for graciously permittingme to carry on the research\n",
            "work and providing facilities in the university to carry out the seminar work suc-\n",
            "cessfully. I am highly grateful to Dr. Ashutosh Tripathi, HoD, Electronics\n",
            "and Communication Engineering for permitting me to make the use of fa-\n",
            "\n",
            "cilities available in the department for the smooth conduct of my synopsis work.\n",
            "The constant guidance and encouragement received from my supervisor Dr.\n",
            "\n",
            "Nitin Sharma, Professor, ECE, has been of great help in carrying out the\n",
            "\n",
            "present work and is acknowledged with reverential thanks.\n",
            "\n",
            "iil\n",
            "\f\n",
            "CONTENTS\n",
            "\n",
            "Topic Page No.\n",
            "Certificate i\n",
            "Declaration ii\n",
            "Acknowledgement iii\n",
            "Contents v\n",
            "Abstract vi\n",
            "\n",
            "List of Figures vii\n",
            "\n",
            "List of Tables viii\n",
            "\n",
            "1 INTRODUCTION 1\n",
            "1.1 Human Ear Anatomy 2\n",
            "1.2 Motivation of the Research 3\n",
            "1.3. Ear Recognition Systems 4\n",
            "1.4 Existing Datasets 6\n",
            "1.5 Deep Learning Techniques 10\n",
            "1.5.1 Existing Detection Models 15\n",
            "\n",
            "1.5.1.1 RCNN Family 16\n",
            "\n",
            "1.5.1.2. YOLO Family 18\n",
            "\n",
            "2 LITERATURE REVIEW 22\n",
            "2.1 Existing Techniques for Ear Detection 22\n",
            "2.2 Existing Techniques for Ear Recognition 28\n",
            "\n",
            "3 RESEARCH GAPS AND OBJECTIVES 32\n",
            "3.1 Research Gaps 32\n",
            "3.2 Problem Statement 33\n",
            "3.3 Research Objectives 33\n",
            "\n",
            "4 RESEARCH METHODOLOGY AND WORK PLAN 35\n",
            "\n",
            "iv\n",
            "\f\n",
            "4.1 Research Methodology\n",
            "4.2 Work Plan\n",
            "\n",
            "References\n",
            "\n",
            "35\n",
            "37\n",
            "\n",
            "45\n",
            "\f\n",
            "ABSTRACT\n",
            "\n",
            "Considering the exponential growth of technology, and the need for security\n",
            "and confidentiality, biometrics are a far better option than conventional se-\n",
            "curity measures. As it is necesary to seek to minimize breaches, multimodal\n",
            "biometrics play a vital role, especially when combined with the ear and the face\n",
            "or when paired with the ear and the iris, allowing tech firms to offer the best\n",
            "and easiest way to access the data that cannot be hacked. A face, iris and ears\n",
            "are all strong indicators of identity and differentiation; their combination will\n",
            "enhance security even further. There are, however, several challenges that need\n",
            "to be resolved, especially when utilizing these traits in real-time applications\n",
            "such as hair, ornaments, masks, facial expressions, and datasets collected in a\n",
            "constrained environment. It is also challenging to choose what to prioritize by\n",
            "rejecting the unimportant features in order to combine multiple traits. Finally,\n",
            "recognition models must be capable of detecting and recognizing biometric traits\n",
            "very precisely, and the response time should be as low as possible, which is key\n",
            "for real-time applications.\n",
            "\n",
            "The significant goal of the research is to increase biometric accuracy while main-\n",
            "taining system security by utilising soft computing approaches without requiring\n",
            "users to physically touch anything. Deep-Learning algorithms will be used to\n",
            "extract the complex properties of ears, which are only mildly-sensitive. With\n",
            "the greatest number of participants possible, a custom image dataset will be\n",
            "created, and these images will go through image processing procedures before\n",
            "being given to a deep-learning model. Then, using the ear biometrics that have\n",
            "already been enrolled, the algorithm will anticipate new photos to identify the\n",
            "person. In order to increase the strength of the biometric, ear biometrics can\n",
            "also be paired with any other biometric trait (multimodal). The difficulties can\n",
            "be to establish multiple modes at conjointly while training and accounting for\n",
            "\n",
            "findings like which attributes of individual modes are more crucial than others.\n",
            "\n",
            "vi\n",
            "\f\n",
            "Fig No.\n",
            "\n",
            "Ll\n",
            "1.2\n",
            "1.3\n",
            "1.4\n",
            "\n",
            "1.5\n",
            "\n",
            "4.1\n",
            "4.2\n",
            "\n",
            "List of Figures\n",
            "\n",
            "Figure Caption\n",
            "\n",
            "Anatomy of the outer Ear\n",
            "Ear Recognition System\n",
            "Convolutional Neural Network\n",
            "Architecture of Mask RCNN\n",
            "YOLOV7\n",
            "\n",
            "Research Methodology\n",
            "Tentative Work Plan\n",
            "\n",
            "vii\n",
            "\f\n",
            "List of Tables\n",
            "\n",
            "Table No. Table Caption\n",
            "I Existing datasets for Ear Detection and Recognition\n",
            "\n",
            "II Comparision of various Ear Detection Techniques\n",
            "\n",
            "III Comparision of various Ear Recognition Techniques\n",
            "\n",
            "viii\n",
            "\n",
            "Page No.\n",
            "11\n",
            "\n",
            "27\n",
            "3l\n",
            "\f\n",
            "Chapter 1\n",
            "\n",
            "INTRODUCTION\n",
            "\n",
            "Artificial intelligence is transforming every aspect of our lives, including the way\n",
            "everyone learn, teach, and communicate, as well as healthcare, agriculture, space\n",
            "exploration, automation vehicles, business, e-commerce, social media, banking\n",
            "\n",
            "& finance, as well as gaming and other forms of entertainment. Nevertheless\n",
            "\n",
            " \n",
            "\n",
            "as technology is used more frequently, it is crucial to do it safely and sensibly.\n",
            "The most promising identification approach to recognise the owner in the safest\n",
            "and most reliable way is a biometric system based on pattern recognition that\n",
            "certifies the legitimacy of a user’s ownership by confirming the physiological or\n",
            "behavioural traits and attributes of the individual. If the user chooses to share\n",
            "information or devices with another person, a tangible physiological biometric\n",
            "[1] include passwords, PINs or physical tokens can be shared securly. However,\n",
            "It has often been observed that these proxies usually are made by the wrong\n",
            "persons and the owner ends up losing the device or information.\n",
            "\n",
            "Biometric features have proven to be a dependable and helpful approach in\n",
            "the case of personal and national security, criminal situations, or terrorism.\n",
            "Biometric identification methods based on biological traits include fingerprint\n",
            "recognition, automatic licence plate recognition [2, 3], hand geometry, Iris recog-\n",
            "nition [4], handwritten charater recognition [5] palm vein recognition, eye vein\n",
            "recognition, DNA matching, face recognition [(, 7], retinal scan, and sound au-\n",
            "thentication of the ears. While it is true that deep learning outperforms other\n",
            "techniques in detection and identification tasks, this does not mean that other\n",
            "algorithms are inherently bad. In fact, using a hybrid strategy increases the\n",
            "likelihood of better results for the same objective [8, 9]. Ears were once consid-\n",
            "\n",
            "ered and approved for use as biometric features, but little attention was paid to\n",
            "\f\n",
            "   \n",
            "\n",
            "Triangular\n",
            "fossa\n",
            "Tubercle\n",
            "of helix ¥, Crus of helix\n",
            "\n",
            "7 Crura of\n",
            "antihelix\n",
            "\n",
            "   \n",
            " \n",
            " \n",
            " \n",
            "\n",
            "hi\n",
            "Scapha Ant. incisure\n",
            "\n",
            "Tubercle of tragus\n",
            "\n",
            "Tragus\n",
            "\n",
            "  \n",
            "\n",
            "> Ext. meatus\n",
            "\n",
            "ntertragal incisure\n",
            "\n",
            "Figure 1.1: Anatomy of the outer Ear\n",
            "[10]\n",
            "\n",
            "them. Recently, work on this feature has increased exponentially, and because\n",
            "of the several benefits that were seen at the pendamic in 2020, it is now even\n",
            "more preferred over other biometric traits.\n",
            "\n",
            "The stability of the ear’s structure, which remains essentially unchanged for\n",
            "up to 60 years, is one of the main benefits of employing ears as biometrics.\n",
            "Furthermore, whereas the features of the face and eyes change according to\n",
            "emotions and the environment, alterations to the ears are minimal. One more\n",
            "benefit of ear biometrics over other biometrics is how simple it is to enroll. First,\n",
            "there are no physical contacts necessary to collect the information of any specific\n",
            "individual, and most importantly, the user does not need to pay attention or\n",
            "coordinate their actions, which is usually quite difficult to do in cases where\n",
            "in fact, children and people who are not comfortable using this most recent\n",
            "\n",
            "technology are involved.\n",
            "\n",
            "1.1 Human Ear Anatomy\n",
            "\n",
            "Every person’s uniqueness is attributed to a variety of ear features, which vary\n",
            "according to ear size, colour, and shape. Pinna, also known as an auricle, and\n",
            "external acoustic meatus, are the two distinct parts of the external ear anatomy,\n",
            "\n",
            "responsible for the biometrics.\n",
            "\f\n",
            "e Lobule: It is the lowest part of the ear, also known as the earlobe. The\n",
            "ear’s blood supply is greater than the rest of the ear. It’s the only part of\n",
            "\n",
            "the outer ear that doesn’t have cartilage to support it.\n",
            "\n",
            "e Helix: The cartilaginous part of the auricle forms the outermost curva-\n",
            "ture of the ear known as Helix, extending from where the ear joins the\n",
            "\n",
            "head at the top to where it meets the lobule.\n",
            "\n",
            "e Antiheliz: A Y-shaped curved cartilaginous ridge that extends from the\n",
            "antitragus and connects the concha, triangular fossa, and scapha. The\n",
            "antihelix is a folding of the conchal cartilage that has the same prominence\n",
            "as a well-developed helix.The volume and degree of folding of an antihelix\n",
            "\n",
            "fluctuates widely between individuals.[11]\n",
            "\n",
            "e Concha: The concha is the depressed area at the opening of the middle\n",
            "\n",
            "ear, or the external acoustic meatus.\n",
            "\n",
            "e Scapha: The trench between the helix and the antihelix. Scapha also\n",
            "\n",
            "varies a lot between individuals.\n",
            "\n",
            " \n",
            "\n",
            "e Tragus: A posterior, slightly inferior, protrusion of skin-covered cartilage,\n",
            "anterior to the auditory meatus. The inferoposterior margin of the tragus\n",
            "\n",
            "forms the anterior wall of the incisura.\n",
            "\n",
            "e Antitragus: The arch-shaped cartilage structure opposite and behind\n",
            "\n",
            "the Tragus is known as the antitragus.\n",
            "\n",
            "e Traingular Fossa: The concavity bounded by the superior and inferior\n",
            "crura of the antihelix and the ascending portion of the helix is known as\n",
            "Triangular Fossa. Everybody’s external lobule and ear’s specific dimen-\n",
            "sions and form are unique, and this distinction is the basis for using the\n",
            "ear as a biometric. The reason the ear is employed as a biometric trait is\n",
            "because all of the components vary substantially in size and form between\n",
            "\n",
            "individuals.\n",
            "\n",
            "1.2 Motivation of the Research\n",
            "\n",
            "Almost everyone nowadays has access to multiple accounts, which can be further\n",
            "subdivided into two types: some accounts that a person wants to share with\n",
            "\n",
            "family or friends, while there are also some accounts that are confidential, such\n",
            "\f\n",
            "as a bank account or a mobile device, that the individual would never want to\n",
            "share. The necessity for exquisite protection for the accounts, especially in the\n",
            "financial field, is supremely important when considering these reports, which\n",
            "are not even for all of the countries in the globe. Biometrics is one of the\n",
            "best strategies to lessen these breaches. Biometrics is one of the finest ways\n",
            "to prevent these breaches, which makes it necessary to implement rather than\n",
            "merely a choice. Biometrics can be used to determine a person’s identity based\n",
            "on many biological characteristics such as their face [12], their fingerprints [13],\n",
            "their iris, their ears, etc. However, in order to make the biometrics even stronger\n",
            "and safer, multimodal biometrics can also be used, which involves identifying\n",
            "multiple biometric traits and matching them. Despite being a new biometric\n",
            "trait, ears show a significant advantage over other biometric traits since masks\n",
            "are not used by everyone or its characteristics are constant across a wide age\n",
            "range [14]. Despite being a new feature, ears are already showing a great deal\n",
            "of potential, which is why it seems like an ideal time to work on ear biometrics.\n",
            "To determine how much fraud occurs in European countries when using credit\n",
            "cards, a survey was undertaken. Ireland has the worst situation, with 88 out of\n",
            "every 1000 people losing money, while transactions have resulted in recorded\n",
            "losses of €7,949 there. Also as per reports, frauds were more prevalent in\n",
            "France. According to the survey, there are 83 instances of fraud for every\n",
            "1,000 credit cards in France, resulting in a total loss of € 5,521 [15]. The study\n",
            "clearly demonstrates the necessity for secure biometrics where we may save our\n",
            "information and money without worry for a considerable amount of time. All of\n",
            "\n",
            "this encourages us to conduct research on a novel, enduring biometric feature.\n",
            "\n",
            "1.3. Ear Recognition Systems\n",
            "\n",
            "The process of identifying an ear mainly involves two steps. The algorithm must\n",
            "first identify the ear from the image, which involves a number of processes be-\n",
            "ginning with the dataset construction with properly labelled photographs taken\n",
            "in an unconstrained environment with the cooperation of as many individuals\n",
            "as feasible. These photos are then prepared for feeding to the deep learning\n",
            "technique by going through several preprocessing procedures including rescal-\n",
            "ing, normalisation, segmentation, etc. Now, the deep learning model extracts\n",
            "the features to determine the individual’s ear’s uniqueness, which is then pro-\n",
            "\n",
            "vided on to the dataset building phase of the system to complete the registration\n",
            "\f\n",
            " \n",
            "\n",
            "Training Phase\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "    \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "Preprocessing Feature\n",
            "+ Normalization Segmentation) mented] &Xtraction\n",
            "+ Resizing —_[Dataset,| USING Ear using\n",
            "Augmentation Deep |—~— I deep\n",
            "Images) | « annotating Neural Netwok Neural\n",
            "+ Training & Training/\n",
            "Deep\n",
            "Learning\n",
            "Model\n",
            "Test Phase\n",
            "Test Pre-Processing Maching\n",
            "Recognized\n",
            "Image a Segmentation pore =\n",
            "(unlabelled data) * Reshape Threshold image\n",
            "or Real-Time Image * Resize vee\n",
            "using Webcam * Color\n",
            "Conversion\n",
            "\n",
            " \n",
            "\n",
            "Figure 1.2: Ear Recognition System\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "process that will be used later to be used as a biometric. When a person needs\n",
            "\n",
            " \n",
            "\n",
            "to be identified, the second component of the system—basically a union of an\n",
            "\n",
            " \n",
            "\n",
            "ear detection system and a matching system—comes into play. The matching\n",
            "system compares the features that were extracted for this person by the ear de-\n",
            "tector to the features that were present in the dataset for the participants. The\n",
            "\n",
            "system then reflects the individual’s identify based on the threshold matching\n",
            "\n",
            "score [16, 17].\n",
            "\n",
            "Some important asects which needs to be taken care of are:\n",
            "\n",
            "e Datasets: Gathering a large dataset of ear pictures from as many par-\n",
            "\n",
            "ticipants as feasible in an unrestricted setting is the technique’ primary\n",
            "\n",
            "stage. The dataset needs to be sufficiently large to train a deep neural\n",
            "\n",
            "network effectively; otherwise, tiny datasets will result in an overfitting\n",
            "\n",
            "issue. Occlusions such as headphones, earrings, any injury, caps, etc. are\n",
            "\n",
            "another crucial feature to take into account while collecting datasets in\n",
            "\n",
            "order to train the deep network effectively detect and recognise real-world\n",
            "\n",
            "circumstances. The job is not over once you collect the pictures; you still\n",
            "\n",
            "need to properly label them according to their subjects, which is another\n",
            "\n",
            "time-consuming and expensive operation.\n",
            "\n",
            "e Pre-Processing: The images are then prepared for feeding into the neu-\n",
            "\n",
            "a\n",
            "\f\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-accaf931ee80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# iterate through the pages and extract text using Pytesseract\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpytesseract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'eng'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mimage_to_string\u001b[0;34m(image, lang, config, nice, output_type, timeout)\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m     return {\n\u001b[0m\u001b[1;32m    424\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBYTES\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDICT\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBYTES\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDICT\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTRING\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m     }[output_type]()\n\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mrun_and_get_output\u001b[0;34m(image, extension, lang, config, nice, timeout, return_bytes)\u001b[0m\n\u001b[1;32m    286\u001b[0m         }\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0mrun_tesseract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{kwargs['output_filename_base']}{extsep}{extension}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mrun_tesseract\u001b[0;34m(input_filename, output_filename_base, extension, lang, config, nice, timeout)\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTesseractNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mtimeout_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror_string\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTesseractError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mtimeout_manager\u001b[0;34m(proc, seconds)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mseconds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1134\u001b[0;31m                 \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1135\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m                 \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/subprocess.py\u001b[0m in \u001b[0;36m_communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   1977\u001b[0m                             'failed to raise TimeoutExpired.')\n\u001b[1;32m   1978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1979\u001b[0;31m                     \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1980\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zXCArE8kQmSv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}